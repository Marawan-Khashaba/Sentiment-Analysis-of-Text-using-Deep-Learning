{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of CNNFINAL11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZZxHEdQV6j"
      },
      "source": [
        "# Importing The Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTD1mkx5RBbb"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ojswl-3QcQX"
      },
      "source": [
        "# Importing The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUkx6NSzRISA"
      },
      "source": [
        "dataset = pd.read_csv(\"IMDB Dataset.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrZSiMPTR-ha",
        "outputId": "4587178f-4fbf-43c1-f3dd-f0993fe84a96"
      },
      "source": [
        "print(dataset.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKod4hGUteaN"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIwNdAJ_1GIi"
      },
      "source": [
        "def preprocess_text(sen):\n",
        "    # Removing html tags\n",
        "    sentence = remove_tags(sen)\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-o1jipT1KD5"
      },
      "source": [
        "import re\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd1GcJAT1jNE"
      },
      "source": [
        "X = []\n",
        "sentences = list(dataset['review'])\n",
        "for sen in sentences:\n",
        "    X.append(preprocess_text(sen))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxqED1Mg1tRD"
      },
      "source": [
        "y = dataset['sentiment']\n",
        "\n",
        "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GljtG0EhTXFv"
      },
      "source": [
        "# Splitting The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPFvkyuWUHr2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsCAVoD1Qgwj"
      },
      "source": [
        "# Preparing the Embedding Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfpGl00H1394"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words=20000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIFx1dXq2MYw"
      },
      "source": [
        "# Adding 1 because of reserved 0 index\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 256\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVEFg0--dY4o",
        "outputId": "adbafb4f-cd12-4a86-fb6e-d95cf3a9bf81"
      },
      "source": [
        "print('Found %s unique tokens.' % vocab_size)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 92285 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3-cAxQOidBb"
      },
      "source": [
        "# importing the dictionary of words 'glove.6B.200d'\n",
        "from numpy import asarray\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('./glove.6B.200d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split(' ')\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVVzzKbd2lW4"
      },
      "source": [
        "from numpy import zeros\n",
        "embedding_matrix = zeros((vocab_size, 200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhuwuEHl2twf"
      },
      "source": [
        "# Building The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hzK_yKa2zKK"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "embedding_layer = Embedding(vocab_size, 200, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "model.add(embedding_layer)\n",
        "\n",
        "model.add(Conv1D(256, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5hZa6rk3KWe",
        "outputId": "914792c9-0a0b-4af6-a836-7b5a8fa5f584"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 256, 200)          18457000  \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 252, 256)          256256    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 18,713,513\n",
            "Trainable params: 256,513\n",
            "Non-trainable params: 18,457,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we6j7TqN3Llj",
        "outputId": "56f61805-fefd-4981-96bc-077b84508f6a"
      },
      "source": [
        "history = model.fit(X_train, Y_train, batch_size=128, epochs=11, verbose=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/11\n",
            "313/313 [==============================] - 147s 468ms/step - loss: 0.3840 - acc: 0.8230\n",
            "Epoch 2/11\n",
            "313/313 [==============================] - 147s 470ms/step - loss: 0.2473 - acc: 0.9016\n",
            "Epoch 3/11\n",
            "313/313 [==============================] - 146s 467ms/step - loss: 0.1840 - acc: 0.9332\n",
            "Epoch 4/11\n",
            "313/313 [==============================] - 145s 463ms/step - loss: 0.1275 - acc: 0.9617\n",
            "Epoch 5/11\n",
            "313/313 [==============================] - 145s 464ms/step - loss: 0.0829 - acc: 0.9827\n",
            "Epoch 6/11\n",
            "313/313 [==============================] - 149s 475ms/step - loss: 0.0510 - acc: 0.9945\n",
            "Epoch 7/11\n",
            "313/313 [==============================] - 149s 475ms/step - loss: 0.0301 - acc: 0.9987\n",
            "Epoch 8/11\n",
            "313/313 [==============================] - 148s 474ms/step - loss: 0.0182 - acc: 0.9997\n",
            "Epoch 9/11\n",
            "313/313 [==============================] - 151s 481ms/step - loss: 0.0116 - acc: 1.0000\n",
            "Epoch 10/11\n",
            "313/313 [==============================] - 150s 479ms/step - loss: 0.0080 - acc: 1.0000\n",
            "Epoch 11/11\n",
            "313/313 [==============================] - 149s 477ms/step - loss: 0.0057 - acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HGLNWzs_6sI"
      },
      "source": [
        "# Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv_TuYTuBTs-",
        "outputId": "1f356284-4978-4d87-cc62-617a29ca6ea6"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "cm =confusion_matrix(y_pred, Y_test)\n",
        "cm\n",
        "print(classification_report(y_pred,Y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      0.90      0.90      5050\n",
            "        True       0.89      0.90      0.90      4950\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0HTe-6rZiut",
        "outputId": "b2985679-a9d6-404b-c356-c705dbc44c8b"
      },
      "source": [
        "results = model.evaluate(X_test,Y_test,batch_size=128)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 14s 180ms/step - loss: 0.3230 - acc: 0.8971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaOvbP1aYl5U",
        "outputId": "4119d847-40e3-479a-8810-3c228779229f"
      },
      "source": [
        "from sklearn.metrics import precision_score , recall_score, f1_score\n",
        "print(f1_score(Y_test,y_pred))\n",
        "print('f1------')\n",
        "print(recall_score(Y_test,y_pred))\n",
        "print('RECAL------')\n",
        "print(precision_score(Y_test,y_pred))\n",
        "print('PRECISION------')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8962178517397882\n",
            "f1------\n",
            "0.8948640483383686\n",
            "RECAL------\n",
            "0.8975757575757576\n",
            "PRECISION------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}